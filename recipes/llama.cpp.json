{
  "meta": {
    "source": "https://github.com/ggml-org/llama.cpp",
    "package": "ggml-org/llama.cpp",
    "tag_filter": "^b\\d+$",
    "date": "2025-12-19T05:36:46Z",
    "target": "",
    "description": "LLM inference in C/C++"
  },
  "version": "7476",
  "method": "fetch_content",
  "url": "https://github.com/ggml-org/llama.cpp/archive/refs/tags/v{{version}}.zip",
  "url_hash": "SHA256=7f7a0c7fb2c0b5986aeb51f38f3cc52cc2b4e6f6bf6fb244346e2ff2a207b396",
  "update_disconnected": true,
  "options": {}
}